{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp review comment rating prediction\n",
    "\n",
    "Author: Kuo Tian, Mengyuan Wang, Haotian Zhou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrap yelp review data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup library imports\n",
    "import io, time, json\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get web page html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def retrieve_html(url):\n",
    "    \"\"\"\n",
    "    Return the raw HTML at the specified URL.\n",
    "\n",
    "    Args:\n",
    "        url (string): \n",
    "\n",
    "    Returns:\n",
    "        status_code (integer):\n",
    "        raw_html (string): the raw HTML content of the response, properly encoded according to the HTTP headers.\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    return response.status_code, response.text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read yelp API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_api_key(filepath=\"yelp_api_key.txt\"):\n",
    "    \"\"\"\n",
    "    Read the Yelp API Key from file.\n",
    "    \n",
    "    Args:\n",
    "        filepath (string): File containing API Key\n",
    "    Returns:\n",
    "        api_key (string): The API Key\n",
    "    \"\"\"\n",
    "    \n",
    "    # Feel free to modify this function if you are storing the API Key differently\n",
    "    return Path(filepath).read_text().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get yelp business Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yelp_search(api_key, query):\n",
    "    \"\"\"\n",
    "    Make an authenticated request to the Yelp API.\n",
    "\n",
    "    Args:\n",
    "        query (string): Search term\n",
    "\n",
    "    Returns:\n",
    "        total (integer): total number of businesses on Yelp corresponding to the query\n",
    "        businesses (list): list of dicts representing each business\n",
    "    \"\"\"\n",
    "    url = \"https://api.yelp.com/v3/businesses/search\"\n",
    "    headers = {\"Authorization\" : \"Bearer %s\" % (api_key)}\n",
    "    params = {\"location\" : query}\n",
    "    response = requests.get(url, params = params, headers = headers)\n",
    "    result = json.loads(response.text)\n",
    "    return result[\"total\"], result[\"businesses\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all restaurants business information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_restaurants(api_key, query):\n",
    "    \"\"\"\n",
    "    Retrieve ALL the restaurants on Yelp for a given query.\n",
    "\n",
    "    Args:\n",
    "        query (string): Search term\n",
    "\n",
    "    Returns:\n",
    "        results (list): list of dicts representing each business\n",
    "    \"\"\"\n",
    "    url = \"https://api.yelp.com/v3/businesses/search\"\n",
    "    headers = {\"Authorization\" : \"Bearer %s\" % (api_key)}\n",
    "    offset = 0\n",
    "    params = {\"location\" : query, \"categories\": \"restaurants\", \"limit\": 40}\n",
    "    response = requests.get(url, params = params, headers = headers)\n",
    "    result = json.loads(response.text)\n",
    "    total = result[\"total\"]\n",
    "    final = []\n",
    "    \n",
    "    while offset<total:\n",
    "        params[\"offset\"] = offset\n",
    "        response = requests.get(url, params = params, headers = headers)\n",
    "        offset += 40\n",
    "        result = json.loads(response.text)\n",
    "        final += result[\"businesses\"]\n",
    "        time.sleep(0.2)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get urls from business information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_api_response(data):\n",
    "    \"\"\"\n",
    "    Parse Yelp API results to extract restaurant URLs.\n",
    "    \n",
    "    Args:\n",
    "        data (string): String of properly formatted JSON.\n",
    "\n",
    "    Returns:\n",
    "        (list): list of URLs as strings from the input JSON.\n",
    "    \"\"\"\n",
    "    \n",
    "    return [ele[\"url\"] for ele in data]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse html page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_page(html):\n",
    "\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    \n",
    "    result = []\n",
    "    reviews = soup.find_all(\"script\",attrs={\"type\":\"application/ld+json\"})[0]\n",
    "    reviews = json.loads(reviews.contents[0])\n",
    "    reviews_count = reviews[\"aggregateRating\"][\"reviewCount\"]\n",
    "    reviews = reviews[\"review\"]\n",
    "    for review in reviews:\n",
    "        tmp = {}\n",
    "        tmp[\"author\"] = review[\"author\"]\n",
    "        tmp[\"rating\"] = float(review[\"reviewRating\"][\"ratingValue\"])\n",
    "        tmp[\"date\"] = review[\"datePublished\"]\n",
    "        tmp[\"description\"] = review[\"description\"]\n",
    "        result.append(tmp)\n",
    "         \n",
    "    return result, math.ceil(reviews_count/20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract yelp review from html pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_reviews(url):\n",
    "    \"\"\"\n",
    "    Retrieve ALL of the reviews for a single restaurant on Yelp.\n",
    "\n",
    "    Parameters:\n",
    "        url (string): Yelp URL corresponding to the restaurant of interest.\n",
    "\n",
    "    Returns:\n",
    "        reviews (list): list of dictionaries containing extracted review information\n",
    "    \"\"\"\n",
    "    tmp, pages = parse_page(retrieve_html(url)[1])\n",
    "    res = []\n",
    "    for i in range(pages):\n",
    "        print(f\"parsing - {i} page\")\n",
    "        if i>10:\n",
    "            break\n",
    "        if i>0:\n",
    "            current, tmp_count = parse_page(retrieve_html(url+\"?start=\"+str(20*i))[1])\n",
    "        else:\n",
    "            current = tmp\n",
    "        res+=current\n",
    "    \n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start scrap yelp review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search restaurants in Duquesne Heights, Pittsburgh :\n",
      "Start extract reviews:\n",
      "Running into error!\n",
      "Running into error!\n",
      "Running into error!\n",
      "Running into error!\n",
      "Running into error!\n",
      "Running into error!\n",
      "Running into error!\n",
      "Running into error!\n",
      "Running into error!\n",
      "Running into error!\n",
      "Running into error!\n",
      "Running into error!\n",
      "Running into error!\n",
      "Running into error!\n",
      "Running into error!\n",
      "Running into error!\n",
      "Running into error!\n",
      "Running into error!\n",
      "Running into error!\n",
      "Running into error!\n",
      "Running into error!\n",
      "Running into error!\n",
      "Running into error!\n",
      "Running into error!\n",
      "Running into error!\n",
      "Running into error!\n",
      "Running into error!\n",
      "Running into error!\n"
     ]
    }
   ],
   "source": [
    "api_key = read_api_key()\n",
    "places = ['Shadyside, Pittsburgh','Downtown, Pittsburgh', 'Strip District, Pittsburgh', 'Point Breeze, Pittsburgh']\n",
    "\n",
    "for place in places:\n",
    "    print(f\"Search restaurants in {place} :\")\n",
    "    businesses = all_restaurants(api_key, place)\n",
    "    urls = parse_api_response(businesses)\n",
    "\n",
    "    print(\"Start extract reviews:\")\n",
    "    with open(place+\".review\",\"w\") as fd:\n",
    "        for url in urls:\n",
    "            try:\n",
    "                reviews = extract_reviews(url)\n",
    "                print(f\"reviews number: {len(reviews)}\")\n",
    "                for review in reviews:\n",
    "                    fd.write(json.dumps(review)+\"\\n\")\n",
    "            except:\n",
    "                print(\"Running into error!\")\n",
    "                continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform review data file from json to csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "file_names = [\"Shadyside, Pittsburgh.review\", \"Downtown, Pittsburgh.review\", 'Strip District, Pittsburgh.review', 'Point Breeze, Pittsburgh.review']\n",
    "\n",
    "entire_review_data = []\n",
    "\n",
    "for file_name in file_names:\n",
    "    with open(file_name, \"r\") as fd:\n",
    "        line = fd.readline()\n",
    "        while line :\n",
    "            review_dict = json.loads(line)\n",
    "            text, rating = review_dict[\"description\"], review_dict[\"rating\"]\n",
    "            text = text.replace(\"\\\"\",\"\\'\").replace(\"\\n\", \"\")\n",
    "            entire_review_data.append([rating, text])\n",
    "            line = fd.readline()\n",
    "\n",
    "def write_csv_file(file_name, review_data):\n",
    "    with open(file_name, \"w\") as fd:\n",
    "        fd.write(\"rating,text\\n\")\n",
    "        for rating, text in review_data:\n",
    "            fd.write(\"\\\"\"+str(rating)+\"\\\"\"+\",\"+\"\\\"\"+text+\"\\\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset to train, dev and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(entire_review_data, test_size=0.3, random_state=15618)\n",
    "\n",
    "write_csv_file(\"Pittsburgh_review.train\", train_data)\n",
    "write_csv_file(\"Pittsburgh_review.test\", test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BILSTM Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
