{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext import data\n",
    "\n",
    "SEED = 15618\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "TEXT = data.Field(tokenize = \"spacy\")\n",
    "LABEL = data.LabelField(dtype = torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m5igjmSXuZg5"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Ahh it was good, but great?! I wouldn't go that far. To be fair, I prefer spicy, bold flavours where this is upscale comfort food.Everything we ordered was extremely rich, and the drinks were excellent.If I could give this spot 3.5 stars I would.Wouldn't go back, but is recommend it if your in town.\"] [3.0]\n",
      "[\"They have good, strong but not burnt iced coffee and very nice vegan baked goods! I've been lucky enough to try their vegan chocolate chip cookie, fluffed nutter cookie, and the walnut banana bread but the original choc chip cookie is my favorite! One of the best vegan cookies I've had. Have stopped by a couple times during both lunch and a bit later in the afternoon and they weren't too packed, although seating is limited. I would consider this a more take-to-go type of lunch spot rather than a sit down coffee shop.\"] [4.0]\n"
     ]
    }
   ],
   "source": [
    "train_file = \"Pittsburgh_review.train\"\n",
    "test_file = \"Pittsburgh_review.test\"\n",
    "\n",
    "train_data, train_labels = pd.read_csv(train_file)[\"text\"].tolist(), pd.read_csv(train_file)[\"rating\"].tolist()\n",
    "print(train_data[:1], train_labels[:1])\n",
    "\n",
    "test_data, test_labels = pd.read_csv(test_file)[\"text\"].tolist(), pd.read_csv(test_file)[\"rating\"].tolist()\n",
    "print(test_data[:1], test_labels[:1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\t Len:\t 60620 {'text': ['Ahh', 'it', 'was', 'good', ',', 'but', 'great', '?', '!', 'I', 'would', \"n't\", 'go', 'that', 'far', '.', 'To', 'be', 'fair', ',', 'I', 'prefer', 'spicy', ',', 'bold', 'flavours', 'where', 'this', 'is', 'upscale', 'comfort', 'food', '.', 'Everything', 'we', 'ordered', 'was', 'extremely', 'rich', ',', 'and', 'the', 'drinks', 'were', 'excellent', '.', 'If', 'I', 'could', 'give', 'this', 'spot', '3.5', 'stars', 'I', 'would', '.', \"Wouldn't\", 'go', 'back', ',', 'but', 'is', 'recommend', 'it', 'if', 'your', 'in', 'town', '.'], 'label': '3.0'}\n",
      "Test\t Len:\t 25980 {'text': ['They', 'have', 'good', ',', 'strong', 'but', 'not', 'burnt', 'iced', 'coffee', 'and', 'very', 'nice', 'vegan', 'baked', 'goods', '!', 'I', \"'ve\", 'been', 'lucky', 'enough', 'to', 'try', 'their', 'vegan', 'chocolate', 'chip', 'cookie', ',', 'fluffed', 'nutter', 'cookie', ',', 'and', 'the', 'walnut', 'banana', 'bread', 'but', 'the', 'original', 'choc', 'chip', 'cookie', 'is', 'my', 'favorite', '!', 'One', 'of', 'the', 'best', 'vegan', 'cookies', 'I', \"'ve\", 'had', '.', 'Have', 'stopped', 'by', 'a', 'couple', 'times', 'during', 'both', 'lunch', 'and', 'a', 'bit', 'later', 'in', 'the', 'afternoon', 'and', 'they', 'were', \"n't\", 'too', 'packed', ',', 'although', 'seating', 'is', 'limited', '.', 'I', 'would', 'consider', 'this', 'a', 'more', 'take', '-', 'to', '-', 'go', 'type', 'of', 'lunch', 'spot', 'rather', 'than', 'a', 'sit', 'down', 'coffee', 'shop', '.'], 'label': '4.0'}\n"
     ]
    }
   ],
   "source": [
    "TRAIN_CSV = \"train_data.csv\"\n",
    "TEST_CSV = \"test_data.csv\"\n",
    "\n",
    "TRAIN_DATA = {\"text\":train_data,\"label\":train_labels}\n",
    "TEST_DATA = {\"text\":test_data,\"label\":test_labels}\n",
    "\n",
    "df_train = DataFrame(TRAIN_DATA,columns = [\"text\",\"label\"])\n",
    "df_train.to_csv(TRAIN_CSV)\n",
    "\n",
    "df_test = DataFrame(TEST_DATA,columns = [\"text\", \"label\"])\n",
    "df_test.to_csv(TEST_CSV)\n",
    "\n",
    "train_dataset = data.TabularDataset(path = TRAIN_CSV,format = \"csv\",fields = [(\"id\",None),(\"text\",TEXT),(\"label\",LABEL)],skip_header = True)\n",
    "test_dataset = data.TabularDataset(path = TEST_CSV,format = \"csv\",fields = [(\"id\",None),(\"text\",TEXT),(\"label\",LABEL)],skip_header = True)\n",
    "\n",
    "print(\"Train\\t\",\"Len:\\t\",len(train_dataset),vars(train_dataset.examples[0]))\n",
    "print(\"Test\\t\" ,\"Len:\\t\",len(test_dataset) ,vars(test_dataset.examples[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT: 5002 LABEL: 5\n",
      "[('.', 497132), ('the', 361237), ('and', 295565), (',', 275940), ('I', 228775), ('a', 226987), ('was', 176786), ('to', 169232), ('of', 127432), ('it', 103924), ('is', 102932), ('for', 95556), ('The', 91197), ('!', 87670), ('in', 83012), ('with', 80289), ('but', 69027), (' ', 65419), ('that', 63509), ('were', 59262)]\n",
      "['<unk>', '<pad>', '.', 'the', 'and', ',', 'I', 'a', 'was', 'to']\n",
      "defaultdict(None, {'5.0': 0, '4.0': 1, '3.0': 2, '2.0': 3, '1.0': 4})\n"
     ]
    }
   ],
   "source": [
    "MAX_VOCAB_SIZE = 5000\n",
    "\n",
    "TEXT.build_vocab(train_dataset,max_size=MAX_VOCAB_SIZE,vectors=\"glove.6B.200d\", unk_init=torch.Tensor.normal_)\n",
    "LABEL.build_vocab(train_dataset)\n",
    "\n",
    "print(\"TEXT:\",len(TEXT.vocab),\"LABEL:\",len(LABEL.vocab))\n",
    "print(TEXT.vocab.freqs.most_common(20))\n",
    "print(TEXT.vocab.itos[:10])\n",
    "print(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator = data.BucketIterator.splits(\n",
    "        (train_dataset, test_dataset),\n",
    "        sort_within_batch=True, \n",
    "        sort_key=lambda x: len(x.text),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "DROP = 0.1\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):       \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)  \n",
    "        self.rnn = nn.LSTM(embedding_dim,hidden_dim,2,dropout = DROP,bidirectional = True)\n",
    "        self.fc = nn.Linear(hidden_dim*2, output_dim)\n",
    "        self.dropout = torch.nn.Dropout(DROP)\n",
    "        \n",
    "    def forward(self, text):\n",
    "      \n",
    "        embedded = self.embedding(text)\n",
    "        output, hidden = self.rnn(embedded)\n",
    "#         res = self.dropout(torch.sum(hidden[0],0))\n",
    "#         print(output.size())\n",
    "        res = self.dropout(torch.mean(output,0))\n",
    "        return self.fc(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 256\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 5\n",
    "\n",
    "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 3,912,709 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "# optimizer = optim.SGD(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    values, indices = torch.max(preds, 1)\n",
    "    res = indices.cpu().detach().numpy()\n",
    "    correct = (y.cpu().detach().numpy()==res)\n",
    "\n",
    "\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    # rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    # correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = sum(correct) / len(correct)\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator: \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(batch.text).squeeze(1)\n",
    "        # _, preds = torch.max(predictions,1)\n",
    "        # print(preds.size())\n",
    "        loss = criterion(predictions, batch.label)\n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            predictions = model(batch.text).squeeze(1)\n",
    "            # _, preds = torch.max(predictions,1)\n",
    "            loss = criterion(predictions, batch.label)\n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 1m 13s\n",
      "\tTrain Loss: 0.575 | Train Acc: 76.20%\n",
      "\t Val. Loss: 0.129 |  Val. Acc: 95.81%\n",
      "Epoch: 02 | Epoch Time: 1m 14s\n",
      "\tTrain Loss: 0.073 | Train Acc: 97.90%\n",
      "\t Val. Loss: 0.018 |  Val. Acc: 99.66%\n",
      "Epoch: 03 | Epoch Time: 1m 14s\n",
      "\tTrain Loss: 0.024 | Train Acc: 99.37%\n",
      "\t Val. Loss: 0.012 |  Val. Acc: 99.76%\n",
      "Epoch: 04 | Epoch Time: 1m 14s\n",
      "\tTrain Loss: 0.018 | Train Acc: 99.46%\n",
      "\t Val. Loss: 0.013 |  Val. Acc: 99.72%\n",
      "Epoch: 05 | Epoch Time: 1m 14s\n",
      "\tTrain Loss: 0.012 | Train Acc: 99.63%\n",
      "\t Val. Loss: 0.011 |  Val. Acc: 99.70%\n",
      "Epoch: 06 | Epoch Time: 1m 14s\n",
      "\tTrain Loss: 0.004 | Train Acc: 99.88%\n",
      "\t Val. Loss: 0.007 |  Val. Acc: 99.91%\n",
      "Epoch: 07 | Epoch Time: 1m 14s\n",
      "\tTrain Loss: 0.000 | Train Acc: 100.00%\n",
      "\t Val. Loss: 0.007 |  Val. Acc: 99.92%\n",
      "Epoch: 08 | Epoch Time: 1m 14s\n",
      "\tTrain Loss: 0.000 | Train Acc: 100.00%\n",
      "\t Val. Loss: 0.008 |  Val. Acc: 99.92%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 20\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        \n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NLP_hw7.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
